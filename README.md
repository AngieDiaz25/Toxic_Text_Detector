# Toxic Text Detector - Sistema de DetecciÃ³n de Toxicidad

Sistema de anÃ¡lisis de toxicidad en textos que utiliza inteligencia artificial para identificar y clasificar contenido ofensivo, amenazante o daÃ±ino en tiempo real.

## Tabla de Contenidos

- [DescripciÃ³n General](#descripciÃ³n-general)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
- [InstalaciÃ³n](#instalaciÃ³n)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [DocumentaciÃ³n de la API](#documentaciÃ³n-de-la-api)
- [Rendimiento del Modelo](#rendimiento-del-modelo)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Despliegue con Docker](#despliegue-con-docker)
- [Ejemplos de Uso](#ejemplos-de-uso)
- [Desarrollo](#desarrollo)
- [Pruebas](#pruebas)
- [Contribuir](#contribuir)
- [Licencia](#licencia)
- [Contacto](#contacto)

## DescripciÃ³n General

Toxic Text Detector es un sistema de clasificaciÃ³n de toxicidad en textos que analiza contenido de entrada y proporciona:

- **ClasificaciÃ³n de Toxicidad**: Detecta 6 tipos de contenido tÃ³xico usando el modelo toxic-bert
- **AnÃ¡lisis en Tiempo Real**: Respuesta inmediata con porcentajes de confianza
- **Historial de Predicciones**: Almacenamiento persistente de anÃ¡lisis realizados
- **Interfaz Web Intuitiva**: Frontend moderno y responsive para fÃ¡cil interacciÃ³n
- **API REST**: Endpoints documentados para integraciÃ³n con otros sistemas

**VersiÃ³n Actual**: 1.0.0  
**Modelo**: toxic-bert (Hugging Face)  
**Framework**: Transformers + PyTorch  
**Estado**: Listo para producciÃ³n

## CaracterÃ­sticas

### Funcionalidad Principal

#### ClasificaciÃ³n con Modelo Pre-entrenado
- Modelo toxic-bert de Hugging Face
- 6 categorÃ­as de toxicidad:
  - Toxic (TÃ³xico general)
  - Severe Toxic (Toxicidad severa)
  - Obscene (Obsceno)
  - Threat (Amenazas)
  - Insult (Insultos)
  - Identity Hate (Odio por identidad)
- AnÃ¡lisis multiclase con probabilidades por categorÃ­a
- Procesamiento con Transformers y PyTorch

#### Sistema de Historial
- Almacenamiento persistente en SQLite
- Registro de timestamp, texto, resultado y confianza
- Consulta de histÃ³rico mediante API
- Base de datos relacional con SQLAlchemy

#### Interfaz de Usuario
- DiseÃ±o responsive (escritorio, tablet, mÃ³vil)
- Degradado morado moderno y profesional
- VisualizaciÃ³n detallada de resultados
- Historial en tiempo real con actualizaciÃ³n automÃ¡tica
- Indicadores visuales por tipo de toxicidad

### Aspectos TÃ©cnicos Destacados

- Arquitectura API RESTful con FastAPI
- DocumentaciÃ³n automÃ¡tica con Swagger
- DiseÃ±o sin estado para escalabilidad
- Manejo robusto de errores
- CORS habilitado para integraciÃ³n con frontend
- ContainerizaciÃ³n completa con Docker
- Imagen publicada en DockerHub

## Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USUARIO                              â”‚
â”‚                  (Navegador Web)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ HTTP Request/Response
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FRONTEND                               â”‚
â”‚              (HTML + CSS + JavaScript)                   â”‚
â”‚  â€¢ Formulario de entrada de texto                        â”‚
â”‚  â€¢ VisualizaciÃ³n de resultados                           â”‚
â”‚  â€¢ Historial de anÃ¡lisis                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ fetch/axios (JSON)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND - API                           â”‚
â”‚                    (FastAPI)                             â”‚
â”‚                                                          â”‚
â”‚  Endpoints:                                              â”‚
â”‚  â€¢ GET  /           â†’ DocumentaciÃ³n                      â”‚
â”‚  â€¢ POST /predict    â†’ Analizar texto                     â”‚
â”‚  â€¢ GET  /history    â†’ Consultar historial               â”‚
â”‚  â€¢ GET  /health     â†’ Estado del servicio               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â”‚                      â”‚
          â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MODELO IA      â”‚   â”‚   BASE DE DATOS        â”‚
â”‚  (toxic-bert)    â”‚   â”‚     (SQLite3)          â”‚
â”‚                  â”‚   â”‚                        â”‚
â”‚ â€¢ Transformers   â”‚   â”‚  Tabla: predictions    â”‚
â”‚ â€¢ PyTorch        â”‚   â”‚  â€¢ id                  â”‚
â”‚ â€¢ Pre-entrenado  â”‚   â”‚  â€¢ timestamp           â”‚
â”‚                  â”‚   â”‚  â€¢ text                â”‚
â”‚ CategorÃ­as:      â”‚   â”‚  â€¢ is_toxic            â”‚
â”‚ â€¢ toxic          â”‚   â”‚  â€¢ main_category       â”‚
â”‚ â€¢ severe_toxic   â”‚   â”‚  â€¢ confidence          â”‚
â”‚ â€¢ obscene        â”‚   â”‚  â€¢ labels (JSON)       â”‚
â”‚ â€¢ threat         â”‚   â”‚                        â”‚
â”‚ â€¢ insult         â”‚   â”‚                        â”‚
â”‚ â€¢ identity_hate  â”‚   â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCKER                                â”‚
â”‚              (Contenedor aislado)                        â”‚
â”‚  â€¢ Empaqueta toda la aplicaciÃ³n                          â”‚
â”‚  â€¢ Portabilidad garantizada                              â”‚
â”‚  â€¢ Imagen publicada en DockerHub                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

1. **Entrada del Usuario**: Mensaje recibido en el frontend
2. **EnvÃ­o a Backend**: POST request a `/predict` con JSON
3. **Preprocesamiento**: ValidaciÃ³n de entrada con Pydantic
4. **AnÃ¡lisis del Modelo**: toxic-bert procesa el texto
5. **ClasificaciÃ³n**: PredicciÃ³n con probabilidades por categorÃ­a
6. **Almacenamiento**: Resultado guardado en SQLite
7. **Respuesta JSON**: Datos enviados al frontend
8. **VisualizaciÃ³n**: Usuario ve resultados formateados

## Stack TecnolÃ³gico

### Backend

| Componente | TecnologÃ­a | VersiÃ³n |
|------------|-----------|---------|
| Framework | FastAPI | 0.104.1 |
| Servidor ASGI | Uvicorn | 0.24.0 |
| ML Framework | Transformers | 4.35.2 |
| Deep Learning | PyTorch | 2.1.1 |
| ORM | SQLAlchemy | 2.0.23 |
| ValidaciÃ³n | Pydantic | 2.5.0 |
| Base de Datos | SQLite3 | Built-in |
| Procesamiento NumÃ©rico | NumPy | <2.0 |

### Frontend

- **Marcado**: HTML5
- **Estilos**: CSS3 con gradientes personalizados
- **Scripting**: JavaScript Vanilla (ES6+)
- **Fuentes**: Sans-serif del sistema
- **Colores**: Degradado morado (#667eea â†’ #764ba2)

### DevOps y Despliegue

- **ContainerizaciÃ³n**: Docker
- **Registry**: DockerHub (angiediazs/toxic-text-detector)
- **Control de Versiones**: Git/GitHub
- **TamaÃ±o de Imagen**: 8.2GB (incluye modelo completo)

### Herramientas de Desarrollo

- **Editor de CÃ³digo**: Visual Studio Code
- **Pruebas de API**: cURL, Postman
- **DevTools de Navegador**: Chrome/Safari Inspector
- **GestiÃ³n de Paquetes**: pip

## InstalaciÃ³n

### Prerequisitos

- Python 3.11 o superior
- pip (gestor de paquetes de Python)
- Git
- Docker (opcional, para deployment)

### OpciÃ³n 1: InstalaciÃ³n Local

#### 1. Clonar el repositorio

```bash
git clone https://github.com/AngieDiaz25/Toxic_Text_Detector.git
cd Toxic_Text_Detector
```

#### 2. Crear entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

#### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

**Nota**: La primera vez que ejecutes la aplicaciÃ³n, el modelo toxic-bert se descargarÃ¡ automÃ¡ticamente (~500MB). Esto puede tardar varios minutos.

#### 4. Ejecutar la aplicaciÃ³n

```bash
uvicorn app.main:app --reload
```

La aplicaciÃ³n estarÃ¡ disponible en `http://localhost:8000`

### OpciÃ³n 2: Usando Docker

#### 1. Descargar imagen desde DockerHub

```bash
docker pull angiediazs/toxic-text-detector:latest
```

#### 2. Ejecutar contenedor

```bash
docker run -d -p 8000:8000 --name toxic-detector angiediazs/toxic-text-detector:latest
```

#### 3. Acceder a la aplicaciÃ³n

Abrir navegador en `http://localhost:8000`

#### 4. Detener contenedor

```bash
docker stop toxic-detector
docker rm toxic-detector
```

## ConfiguraciÃ³n

### Variables de Entorno

Actualmente no se requieren variables de entorno. La aplicaciÃ³n funciona out-of-the-box.

### ConfiguraciÃ³n de Base de Datos

La base de datos SQLite se crea automÃ¡ticamente en la primera ejecuciÃ³n:

```
predictions.db
```

**Esquema de la tabla `predictions`:**

```sql
CREATE TABLE predictions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    text TEXT NOT NULL,
    is_toxic BOOLEAN NOT NULL,
    main_category VARCHAR(50),
    confidence FLOAT,
    labels TEXT  -- JSON serializado
);
```

## DocumentaciÃ³n de la API

### URL Base

- **Local**: `http://localhost:8000`
- **Docker**: `http://localhost:8000`

### Endpoints

#### 1. PÃ¡gina Principal

```
GET /
```

**Respuesta**: HTML con interfaz web completa

---

#### 2. VerificaciÃ³n de Estado

```
GET /health
```

**Respuesta de Ã‰xito (200 OK)**:

```json
{
  "status": "healthy",
  "model": "toxic-bert",
  "version": "1.0.0"
}
```

---

#### 3. Predecir Toxicidad

```
POST /predict
Content-Type: application/json
```

**Cuerpo de la Solicitud**:

```json
{
  "text": "You are stupid!"
}
```

**Respuesta de Ã‰xito (200 OK)**:

```json
{
  "text": "You are stupid!",
  "is_toxic": true,
  "main_category": "toxic",
  "confidence": 0.9882,
  "labels": {
    "toxic": 0.9882,
    "insult": 0.9526,
    "obscene": 0.728,
    "severe_toxic": 0.0366,
    "identity_hate": 0.0124,
    "threat": 0.0013
  }
}
```

**Respuesta de Error (400 Bad Request)**:

```json
{
  "detail": "El texto no puede estar vacÃ­o"
}
```

**Respuesta de Error (500 Internal Server Error)**:

```json
{
  "detail": "Error interno del servidor"
}
```

---

#### 4. Obtener Historial

```
GET /history?limit=10
```

**ParÃ¡metros de Query**:
- `limit` (opcional): NÃºmero de resultados a retornar (default: 10, max: 100)

**Respuesta de Ã‰xito (200 OK)**:

```json
{
  "total": 3,
  "predictions": [
    {
      "id": 3,
      "timestamp": "2024-12-04T12:30:45",
      "text": "You are stupid!",
      "is_toxic": true,
      "main_category": "toxic",
      "confidence": 0.9882,
      "labels": {
        "toxic": 0.9882,
        "insult": 0.9526,
        "obscene": 0.728,
        "severe_toxic": 0.0366,
        "identity_hate": 0.0124,
        "threat": 0.0013
      }
    },
    ...
  ]
}
```

---

#### 5. DocumentaciÃ³n Interactiva (Swagger)

```
GET /docs
```

Interfaz interactiva de Swagger UI para probar todos los endpoints.

---

### CÃ³digos de Estado HTTP

| CÃ³digo | Significado |
|--------|-------------|
| 200 | OK - Solicitud exitosa |
| 400 | Bad Request - Datos invÃ¡lidos |
| 500 | Internal Server Error - Error del servidor |

## Rendimiento del Modelo

### Modelo: toxic-bert (unitary/toxic-bert)

**InformaciÃ³n General**:
- **Fuente**: Hugging Face Model Hub
- **Arquitectura**: BERT (Bidirectional Encoder Representations from Transformers)
- **Entrenamiento**: Pre-entrenado en datasets de toxicidad de gran escala
- **ParÃ¡metros**: ~110M parÃ¡metros
- **Idioma**: Optimizado para inglÃ©s (funciona con otros idiomas con menor precisiÃ³n)

### CategorÃ­as de ClasificaciÃ³n

El modelo clasifica el texto en 6 categorÃ­as de toxicidad:

| CategorÃ­a | DescripciÃ³n | Ejemplos |
|-----------|-------------|----------|
| **toxic** | Toxicidad general | Lenguaje rudo, agresivo |
| **severe_toxic** | Toxicidad severa | Contenido extremadamente ofensivo |
| **obscene** | Contenido obsceno | Lenguaje vulgar, sexual |
| **threat** | Amenazas | Amenazas de violencia |
| **insult** | Insultos | Ataques personales directos |
| **identity_hate** | Odio por identidad | DiscriminaciÃ³n por raza, religiÃ³n, etc. |

### Umbrales de Confianza

- **Alto** (>0.7): ClasificaciÃ³n muy confiable
- **Medio** (0.4-0.7): ClasificaciÃ³n moderadamente confiable
- **Bajo** (<0.4): ClasificaciÃ³n de baja confianza

### Limitaciones del Modelo

- Optimizado principalmente para texto en inglÃ©s
- Puede tener dificultad con sarcasmo o ironÃ­a
- El contexto cultural puede afectar la precisiÃ³n
- Sesgo potencial hacia ciertos tipos de lenguaje o comunidades
- No detecta toxicidad implÃ­cita o muy sutil

## Estructura del Proyecto

```
Toxic_Text_Detector/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py              # InicializaciÃ³n del paquete
â”‚   â”œâ”€â”€ main.py                  # AplicaciÃ³n FastAPI principal
â”‚   â”œâ”€â”€ inference.py             # Clase ToxicityDetector
â”‚   â”œâ”€â”€ database.py              # ConfiguraciÃ³n de SQLAlchemy
â”‚   â”œâ”€â”€ models.py                # Modelos de base de datos
â”‚   â””â”€â”€ schemas.py               # Esquemas Pydantic
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html               # Estructura HTML
â”‚   â”œâ”€â”€ style.css                # Estilos CSS
â”‚   â””â”€â”€ script.js                # LÃ³gica JavaScript
â”œâ”€â”€ .dockerignore                # Archivos ignorados por Docker
â”œâ”€â”€ .gitignore                   # Archivos ignorados por Git
â”œâ”€â”€ Dockerfile                   # Instrucciones de construcciÃ³n Docker
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ test_model.py                # Script de prueba del modelo
â”œâ”€â”€ predictions.db               # Base de datos SQLite (generado)
â””â”€â”€ README.md                    # Este archivo
```

### DescripciÃ³n de Archivos Clave

**app/main.py**: 
- AplicaciÃ³n principal de FastAPI
- Define endpoints REST
- Integra modelo, base de datos y frontend
- ConfiguraciÃ³n de CORS

**app/inference.py**:
- Clase `ToxicityDetector`
- Carga y gestiÃ³n del modelo toxic-bert
- MÃ©todo `predict()` para clasificaciÃ³n
- Procesamiento de resultados

**app/database.py**:
- ConfiguraciÃ³n de SQLAlchemy
- CreaciÃ³n de engine y sesiones
- FunciÃ³n `get_db()` para dependency injection

**app/models.py**:
- Modelo ORM `Prediction`
- Esquema de tabla de base de datos
- MÃ©todos helper para JSON

**app/schemas.py**:
- Esquemas Pydantic para validaciÃ³n
- `TextInput`: ValidaciÃ³n de entrada
- `PredictionOutput`: Formato de respuesta

**frontend/**: 
- Interfaz web completa
- DiseÃ±o responsive con CSS Grid
- ComunicaciÃ³n async con API mediante Fetch
- ActualizaciÃ³n en tiempo real del historial

**Dockerfile**:
- Imagen base: `python:3.11-slim`
- InstalaciÃ³n de dependencias
- Copia de cÃ³digo fuente
- ExposiciÃ³n del puerto 8000
- Comando de inicio con uvicorn

## Despliegue con Docker

### ConstrucciÃ³n de la Imagen

```bash
# Construir imagen localmente
docker build -t toxic-text-detector:latest .

# Etiquetar para DockerHub
docker tag toxic-text-detector:latest tu-usuario/toxic-text-detector:latest

# Subir a DockerHub
docker push tu-usuario/toxic-text-detector:latest
```

### EjecuciÃ³n del Contenedor

```bash
# Ejecutar en modo detached
docker run -d -p 8000:8000 --name toxic-detector angiediazs/toxic-text-detector:latest

# Ver logs
docker logs toxic-detector

# Seguir logs en tiempo real
docker logs -f toxic-detector

# Detener contenedor
docker stop toxic-detector

# Eliminar contenedor
docker rm toxic-detector

# Ver contenedores en ejecuciÃ³n
docker ps

# Ver todas las imÃ¡genes
docker images
```

### Docker Compose (Opcional)

Crear `docker-compose.yml`:

```yaml
version: '3.8'

services:
  toxic-detector:
    image: angiediazs/toxic-text-detector:latest
    ports:
      - "8000:8000"
    restart: unless-stopped
    container_name: toxic-detector
```

Ejecutar:

```bash
docker-compose up -d
docker-compose down
```

## Ejemplos de Uso

### Ejemplos con cURL

#### PredicciÃ³n BÃ¡sica

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "Have a wonderful day!"}'
```

#### DetecciÃ³n de Contenido TÃ³xico

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "You are stupid and I hate you!"}'
```

#### Obtener Historial

```bash
curl http://localhost:8000/history?limit=5
```

#### Verificar Estado

```bash
curl http://localhost:8000/health
```

### Ejemplo en Python

```python
import requests

API_URL = "http://localhost:8000/predict"

def analizar_toxicidad(texto):
    response = requests.post(
        API_URL,
        json={"text": texto},
        headers={"Content-Type": "application/json"}
    )
    return response.json()

# Ejemplo de uso
resultado = analizar_toxicidad("You are amazing!")
print(f"Texto: {resultado['text']}")
print(f"Es tÃ³xico: {resultado['is_toxic']}")
print(f"CategorÃ­a principal: {resultado['main_category']}")
print(f"Confianza: {resultado['confidence']:.2%}")
print(f"\nDesglose por categorÃ­a:")
for categoria, score in resultado['labels'].items():
    print(f"  {categoria}: {score:.2%}")
```

### Ejemplo en JavaScript

```javascript
const API_URL = 'http://localhost:8000/predict';

async function analizarToxicidad(texto) {
  try {
    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ text: texto }),
    });
    
    if (!response.ok) {
      throw new Error('Error en la peticiÃ³n');
    }
    
    const datos = await response.json();
    return datos;
  } catch (error) {
    console.error('Error:', error);
    throw error;
  }
}

// Ejemplo de uso
analizarToxicidad('This is a test message')
  .then(resultado => {
    console.log('Es tÃ³xico:', resultado.is_toxic);
    console.log('CategorÃ­a:', resultado.main_category);
    console.log('Confianza:', resultado.confidence);
    console.log('Labels:', resultado.labels);
  })
  .catch(error => {
    console.error('Error al analizar:', error);
  });
```

### IntegraciÃ³n con React

```jsx
import { useState } from 'react';

function ToxicityChecker() {
  const [text, setText] = useState('');
  const [result, setResult] = useState(null);
  const [loading, setLoading] = useState(false);

  const checkToxicity = async () => {
    setLoading(true);
    try {
      const response = await fetch('http://localhost:8000/predict', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text }),
      });
      const data = await response.json();
      setResult(data);
    } catch (error) {
      console.error('Error:', error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div>
      <textarea 
        value={text} 
        onChange={(e) => setText(e.target.value)}
        placeholder="Escribe un texto para analizar..."
      />
      <button onClick={checkToxicity} disabled={loading}>
        {loading ? 'Analizando...' : 'Analizar'}
      </button>
      {result && (
        <div>
          <p>Resultado: {result.is_toxic ? 'TÃ³xico' : 'No tÃ³xico'}</p>
          <p>CategorÃ­a: {result.main_category}</p>
          <p>Confianza: {(result.confidence * 100).toFixed(2)}%</p>
        </div>
      )}
    </div>
  );
}
```

## Desarrollo

### Prerequisitos para Desarrollo

- Python 3.11+
- pip
- Git
- Editor de cÃ³digo (VS Code recomendado)
- Docker (opcional)
- Postman o similar para pruebas de API

### Configurar Entorno de Desarrollo

#### 1. Fork y clonar repositorio

```bash
git clone https://github.com/TU_USUARIO/Toxic_Text_Detector.git
cd Toxic_Text_Detector
```

#### 2. Crear rama de caracterÃ­stica

```bash
git checkout -b feature/nombre-de-tu-caracteristica
```

#### 3. Instalar en modo desarrollo

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### 4. Realizar cambios y probar

```bash
# Ejecutar servidor de desarrollo
uvicorn app.main:app --reload

# En otra terminal, probar cambios
curl http://localhost:8000/health
```

#### 5. Commit con mensajes descriptivos

```bash
git add .
git commit -m "feat: AÃ±adir nueva funcionalidad"
```

#### 6. Push y crear pull request

```bash
git push origin feature/nombre-de-tu-caracteristica
```

### GuÃ­as de Estilo de CÃ³digo

#### Python (Backend)

- Seguir guÃ­a de estilo PEP 8
- Usar type hints donde sea aplicable
- Documentar funciones con docstrings
- Longitud mÃ¡xima de lÃ­nea: 100 caracteres
- Usar f-strings para formateo de strings

```python
# Bueno
def predict(self, text: str) -> Dict:
    """
    Analiza un texto y devuelve predicciÃ³n de toxicidad.
    
    Args:
        text: Texto a analizar
        
    Returns:
        Dict con resultados de la predicciÃ³n
    """
    if not text or len(text.strip()) == 0:
        raise ValueError("El texto no puede estar vacÃ­o")
    ...
```

#### JavaScript (Frontend)

- Usar caracterÃ­sticas ES6+
- Preferir `const` y `let` sobre `var`
- Usar funciones flecha para callbacks
- Documentar funciones complejas con comentarios JSDoc
- Nombres descriptivos de variables

```javascript
// Bueno
const analyzeText = async () => {
    const text = document.getElementById('textInput').value;
    if (!text.trim()) {
        alert('Por favor escribe un texto');
        return;
    }
    ...
};
```

#### CSS

- Usar convenciÃ³n de nomenclatura BEM donde sea aplicable
- DiseÃ±o responsive mobile-first
- Agrupar propiedades relacionadas
- Comentar selectores complejos

### ConvenciÃ³n de Mensajes de Commit

- `feat:` Nueva caracterÃ­stica
- `fix:` CorrecciÃ³n de bug
- `docs:` Cambios en documentaciÃ³n
- `style:` Cambios de estilo de cÃ³digo (formato, etc.)
- `refactor:` RefactorizaciÃ³n de cÃ³digo
- `test:` AÃ±adir o actualizar pruebas
- `chore:` Tareas de mantenimiento

## Pruebas

### Pruebas Manuales del Backend

```bash
# Probar endpoint de estado
curl http://localhost:8000/health

# Probar predicciÃ³n con texto no tÃ³xico
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "Have a nice day!"}'

# Probar predicciÃ³n con texto tÃ³xico
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "You are stupid!"}'

# Probar historial
curl http://localhost:8000/history?limit=5

# Probar caso de error (texto vacÃ­o)
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": ""}'
```

### Pruebas del Frontend

1. Abrir DevTools del navegador (F12)
2. Ir a la pestaÃ±a Console
3. Probar funcionalidad de chat manualmente:
   - Enviar texto vacÃ­o (deberÃ­a validar)
   - Enviar texto tÃ³xico
   - Enviar texto no tÃ³xico
   - Verificar actualizaciÃ³n del historial
   - Hacer clic en botÃ³n "Actualizar"
4. Verificar diseÃ±o responsive:
   - Desktop (>1024px)
   - Tablet (768px-1024px)
   - MÃ³vil (<768px)

### Casos de Prueba Recomendados

#### Textos No TÃ³xicos

```
"Have a wonderful day!"
"This is a great project"
"I love learning new things"
"Thank you for your help"
"Machine learning is fascinating"
```

#### Textos TÃ³xicos

```
"You are stupid!"
"I hate you"
"You are worthless"
"Go to hell"
"You are an idiot"
```

#### Casos Extremos

```
""                          # Texto vacÃ­o
"a"                        # Un solo carÃ¡cter
"ğŸ˜ŠğŸ˜ŠğŸ˜Š"                    # Solo emojis
"AAAA" * 500              # Texto muy largo
"   "                     # Solo espacios
```

### Verificar Rendimiento

```bash
# Medir tiempo de respuesta
time curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "test"}'
```

**Tiempos esperados**:
- Primera predicciÃ³n (carga del modelo): <3000ms
- Predicciones subsecuentes: <500ms
- Docker (primera vez): <5000ms
- Docker (subsecuente): <1000ms

## Contribuir

Las contribuciones son bienvenidas. Por favor, sigue estas pautas:

### CÃ³mo Contribuir

1. Fork del repositorio
2. Crear una rama de caracterÃ­stica (`git checkout -b feature/CaracteristicaAsombrosa`)
3. Realizar tus cambios
4. Probar exhaustivamente
5. Commit de tus cambios (`git commit -m 'feat: AÃ±adir CaracteristicaAsombrosa'`)
6. Push a la rama (`git push origin feature/CaracteristicaAsombrosa`)
7. Abrir un Pull Request

### Pautas para Pull Requests

- Proporcionar descripciÃ³n clara de los cambios
- Referenciar issues relacionados si aplica
- Incluir resultados de pruebas
- Actualizar documentaciÃ³n si es necesario
- Seguir el estilo de cÃ³digo existente
- Asegurar que todas las pruebas pasen

### Reportar Issues

Al reportar issues, por favor incluye:

- DescripciÃ³n clara del problema
- Pasos para reproducir
- Comportamiento esperado vs real
- Detalles del entorno (SO, versiÃ³n de Python, Docker, etc.)
- Mensajes de error o capturas de pantalla si aplica

### Solicitudes de CaracterÃ­sticas

Para solicitudes de caracterÃ­sticas, por favor describe:

- Caso de uso y motivaciÃ³n
- SoluciÃ³n propuesta o enfoque de implementaciÃ³n
- Impacto potencial en funcionalidad existente

## Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver abajo para detalles:

### Licencia MIT

Copyright (c) 2024 Angie DÃ­az

Por la presente se concede permiso, libre de cargos, a cualquier persona que obtenga una copia
de este software y de los archivos de documentaciÃ³n asociados (el "Software"), para utilizar
el Software sin restricciÃ³n, incluyendo sin limitaciÃ³n los derechos de usar, copiar, modificar,
fusionar, publicar, distribuir, sublicenciar, y/o vender copias del Software, y para permitir
a las personas a las que se les proporcione el Software hacer lo mismo, sujeto a las siguientes
condiciones:

El aviso de copyright anterior y este aviso de permiso se incluirÃ¡n en todas las copias o
porciones sustanciales del Software.

EL SOFTWARE SE PROPORCIONA "TAL CUAL", SIN GARANTÃA DE NINGÃšN TIPO, EXPRESA O IMPLÃCITA,
INCLUYENDO PERO NO LIMITADO A GARANTÃAS DE COMERCIALIZACIÃ“N, IDONEIDAD PARA UN PROPÃ“SITO
PARTICULAR Y NO INFRACCIÃ“N. EN NINGÃšN CASO LOS AUTORES O TITULARES DEL COPYRIGHT SERÃN
RESPONSABLES DE NINGUNA RECLAMACIÃ“N, DAÃ‘OS U OTRAS RESPONSABILIDADES, YA SEA EN UNA ACCIÃ“N
DE CONTRATO, AGRAVIO O CUALQUIER OTRO MOTIVO, QUE SURJA DE O EN CONEXIÃ“N CON EL SOFTWARE O
EL USO U OTROS TRATOS EN EL SOFTWARE.

## Consideraciones Ã‰ticas

### Disclaimers Importantes

**Esta es una herramienta de detecciÃ³n, no un sistema de censura:**

- El detector proporciona clasificaciones basadas en patrones aprendidos
- No es un juez absoluto de lo que es "aceptable" o no
- El contexto cultural y social es importante
- Los usuarios deben usar su propio juicio

**Limitaciones de Responsabilidad:**

- El sistema puede tener falsos positivos y falsos negativos
- No detecta todas las formas de toxicidad (sarcasmo, contexto implÃ­cito)
- Optimizado para inglÃ©s, puede tener menor precisiÃ³n en otros idiomas
- No es un sustituto del juicio humano en moderaciÃ³n de contenido

### Privacidad y Datos

- **No se almacenan datos personales**: Solo se guarda el texto analizado y resultados
- **Sin tracking**: No se rastrea informaciÃ³n del usuario
- **API sin estado**: No se mantiene sesiÃ³n entre peticiones
- **Base de datos local**: Los datos permanecen en tu servidor/contenedor
- **Sin cookies**: La aplicaciÃ³n no usa cookies de terceros

### Uso Responsable

Este sistema estÃ¡ diseÃ±ado para:

âœ“ ModeraciÃ³n de contenido en plataformas
âœ“ AnÃ¡lisis de comentarios en redes sociales
âœ“ DetecciÃ³n de contenido ofensivo en chats
âœ“ InvestigaciÃ³n sobre discurso tÃ³xico online
âœ“ EducaciÃ³n sobre comunicaciÃ³n respetuosa

**No debe usarse para:**

âœ— Censura indiscriminada sin revisiÃ³n humana
âœ— DiscriminaciÃ³n o targeting de usuarios
âœ— ViolaciÃ³n de privacidad
âœ— AplicaciÃ³n de polÃ­ticas sin contexto

## Agradecimientos

- **Hugging Face**: Por el modelo toxic-bert y la librerÃ­a Transformers
- **FastAPI**: Por el excelente framework web
- **PyTorch**: Por el framework de deep learning
- **SQLAlchemy**: Por el ORM robusto
- **Docker**: Por la plataforma de containerizaciÃ³n
- **Comunidad Open Source**: Por las innumerables herramientas y recursos

## Hoja de Ruta

### VersiÃ³n 1.1 (Planificada)

- [ ] Soporte multiidioma (espaÃ±ol, francÃ©s, alemÃ¡n)
- [ ] Endpoint para anÃ¡lisis por lotes
- [ ] Exportar historial como CSV/JSON
- [ ] Dashboard de estadÃ­sticas
- [ ] AutenticaciÃ³n bÃ¡sica con API keys

### VersiÃ³n 2.0 (Futuro)

- [ ] Fine-tuning del modelo para dominios especÃ­ficos
- [ ] DetecciÃ³n de intensidad de toxicidad
- [ ] Sistema de reportes detallados
- [ ] IntegraciÃ³n con sistemas de moderaciÃ³n
- [ ] AplicaciÃ³n mÃ³vil (React Native)
- [ ] Panel de administraciÃ³n web

## Contacto

**Autora**: Angie DÃ­az

- **GitHub**: [@AngieDiaz25](https://github.com/AngieDiaz25)
- **Proyecto**: [Toxic_Text_Detector](https://github.com/AngieDiaz25/Toxic_Text_Detector)

**Enlaces del Proyecto**:

- **Repositorio**: https://github.com/AngieDiaz25/Toxic_Text_Detector
- **DockerHub**: https://hub.docker.com/r/angiediazs/toxic-text-detector
- **Issues**: https://github.com/AngieDiaz25/Toxic_Text_Detector/issues

---

**VersiÃ³n**: 1.0.0  
**Ãšltima actualizaciÃ³n**: Diciembre 2024  
**Estado**: Activo y en mantenimiento

---

â­ Si este proyecto te ha sido Ãºtil, por favor dale una estrella en GitHub â­
